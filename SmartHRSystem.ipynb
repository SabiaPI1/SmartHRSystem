{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install keybert\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a3rrVkMLj5om",
        "outputId": "338b744c-6e27-4ef2-9dd9-8e4e381fbc32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: keybert in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.1.31)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from functools import lru_cache\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from keybert import KeyBERT\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "1yNBd743j_nc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели для преобразования текста в векторы\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Инициализация KeyBERT для извлечения ключевых слов\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Инициализация стеммеров для русского и английского языков\n",
        "stemmer_ru = SnowballStemmer('russian')\n",
        "stemmer_en = SnowballStemmer('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QV1xKArAkHYU",
        "outputId": "43d239c2-b6b0-469f-87eb-b1101d0584e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных из JSON-файлов\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Загружает данные из JSON-файлов и преобразует их в структурированный формат.\n",
        "    Возвращает три объекта:\n",
        "    - job_data: словарь вакансий\n",
        "    - specialists_data: список кандидатов\n",
        "    - skill_names: словарь нормализованных навыков\n",
        "    \"\"\"\n",
        "    # Загрузка навыков\n",
        "    with open('skills.json', encoding='utf-8') as f:\n",
        "        skills = json.load(f)\n",
        "\n",
        "    # Загрузка вакансий\n",
        "    with open('jobs.json', encoding='utf-8') as f:\n",
        "        jobs = json.load(f)\n",
        "\n",
        "    # Загрузка данных о кандидатах\n",
        "    with open('specialists.json', encoding='utf-8') as f:\n",
        "        specialists = json.load(f)\n",
        "\n",
        "    # Создание словаря для навыков\n",
        "    skill_names = {\n",
        "        s['_id']['$oid']: {     # Используем уникальный ID навыка как ключ\n",
        "            'ru': s['name']['ru'].lower(),\n",
        "            'en': s['name']['en'].lower()\n",
        "        }\n",
        "        for s in skills\n",
        "    }\n",
        "\n",
        "    # Обработка вакансий\n",
        "    job_data = {}    # Словарь для хранения обработанных вакансий\n",
        "    for job in jobs:\n",
        "        job_id = job['_id']['$oid']  # Получаем уникальный ID вакансии\n",
        "        # Формируем объединенный текст требований вакансии\n",
        "        job_req = ' '.join([\n",
        "            f\"{r['requirement'].get('ru', '')} {r['requirement'].get('en', '')}\"\n",
        "            for r in job['requirements']\n",
        "        ])\n",
        "        # Сохраняем структурированные данные вакансии\n",
        "        job_data[job_id] = {\n",
        "            'requirements': job_req,\n",
        "            'tasks': [t['name']['ru'] for t in job['tasks']],\n",
        "            'mandatory_skills': [\n",
        "                (r['requirement'].get('ru', '').lower(), r['mandatory'])\n",
        "                for r in job['requirements']\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # Обработка данных о кандидатах\n",
        "    specialists_data = []   # Список для хранения профилей кандидатов\n",
        "    for spec in specialists:\n",
        "        skills_list = [skill_names[s]['ru'] for s in spec.get('skills', []) if s in skill_names]\n",
        "        skills_text = '; '.join(skills_list)   # Объединяем навыки в строку\n",
        "\n",
        "        # Расчет опыта работы\n",
        "        experience = {}\n",
        "        for exp in spec['experience']:\n",
        "            try:\n",
        "                # Парсим дату начала работы\n",
        "                start = datetime.fromisoformat(exp['start']['$date']).replace(tzinfo=None)\n",
        "                # Парсим дату окончания (или текущую дату, если нет окончания)\n",
        "                end = (\n",
        "                    datetime.fromisoformat(exp['end']['$date']).replace(tzinfo=None)\n",
        "                    if exp['end']\n",
        "                    else datetime.now().replace(tzinfo=None)\n",
        "                )\n",
        "                months = calculate_experience(start, end)\n",
        "\n",
        "                desc = exp.get('description', {}).get('ru', '') + ' ' + exp.get('description', {}).get('en', '')\n",
        "                # Извлекаем навыки из описания опыта работы\n",
        "                exp_skills = extract_skills(desc, skill_names)\n",
        "\n",
        "                # Аккумулируем опыт по навыкам\n",
        "                for skill in exp_skills:\n",
        "                    experience[skill] = experience.get(skill, 0) + months\n",
        "            except (KeyError, ValueError):\n",
        "                # Пропускаем некорректные записи опыта\n",
        "                continue\n",
        "\n",
        "        specialists_data.append({\n",
        "            'id': spec['_id']['$oid'],\n",
        "            'name': spec['name']['ru'],   # Имя на русском\n",
        "            'skills': skills_text,   # Строка с навыками\n",
        "            'experience': experience   # Словарь опыта\n",
        "        })\n",
        "\n",
        "    return job_data, specialists_data, skill_names"
      ],
      "metadata": {
        "id": "i5b_w3IQx3CH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация навыков\n",
        "def normalize_skill(skill: str) -> str:\n",
        "    # Разделение на русские и английские части\n",
        "    tokens = skill.split()\n",
        "    stemmed = []\n",
        "    for token in tokens:\n",
        "        if re.search('[а-яА-Я]', token):\n",
        "            stemmed.append(stemmer_ru.stem(token))\n",
        "        else:\n",
        "            stemmed.append(stemmer_en.stem(token))\n",
        "    return ' '.join(stemmed)"
      ],
      "metadata": {
        "id": "_-NfcCZ9lLEN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечение ключевых навыков\n",
        "def extract_skills(text: str, skill_db: dict) -> list:\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2)) # Извлечение ключевых слов\n",
        "    validated_skills = []\n",
        "    for kw, _ in keywords:\n",
        "        # Проверка, есть ли ключевое слово в skills.json\n",
        "        for skill_id, skill_names in skill_db.items():\n",
        "            if normalize_skill(kw.lower()) in normalize_skill(skill_names['ru']) or normalize_skill(kw.lower()) in normalize_skill(skill_names['en']):\n",
        "                validated_skills.append(skill_names['ru'])\n",
        "    return list(set(validated_skills))"
      ],
      "metadata": {
        "id": "UTPlZBCllU96"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Расчет опыта работы\n",
        "def calculate_experience(start: datetime, end: datetime) -> int:\n",
        "    delta = relativedelta(end, start)\n",
        "    return min(delta.years * 12 + delta.months, 600)"
      ],
      "metadata": {
        "id": "cqXHxmlllaCr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Семантическое сравнение навыков\n",
        "def calculate_similarity(skill1: str, skill2: str, threshold: float = 0.7) -> bool:\n",
        "    @lru_cache(maxsize=10_000) # Кэширование результатов для ускорения работы\n",
        "    def get_embedding(skill: str):\n",
        "        return model.encode(skill) # Преобразование навыка в вектор\n",
        "\n",
        "    emb1 = get_embedding(skill1)\n",
        "    emb2 = get_embedding(skill2)\n",
        "    return cosine_similarity([emb1], [emb2])[0][0] >= threshold # Сравнение сходства"
      ],
      "metadata": {
        "id": "mZu3Z5Izlczq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Расчет соответствия кандидата вакансии\n",
        "def calculate_match(job, spec, skill_db):\n",
        "    \"\"\"Расчет соответствия\"\"\"\n",
        "    try:\n",
        "        job_skills = extract_skills(job['requirements'], skill_db) # Извлечение навыков из вакансии\n",
        "        candidate_skills = extract_skills(spec['skills'], skill_db) # Извлечение навыков кандидата\n",
        "\n",
        "        if not job_skills:\n",
        "            return {'match_percent': 0, 'matched_skills': [], 'missing_skills': []}\n",
        "\n",
        "        # Проверка обязательных навыков\n",
        "        mandatory_skills = [skill for skill, is_mandatory in job['mandatory_skills'] if is_mandatory]\n",
        "        if not all(skill in candidate_skills for skill in mandatory_skills):\n",
        "            return {'match_percent': 0, 'matched_skills': [], 'missing_skills': job_skills}\n",
        "\n",
        "        # Создаем общий словарь навыков\n",
        "        all_skills = list(set(job_skills + candidate_skills))\n",
        "\n",
        "        # Кодируем все навыки\n",
        "        skill_embeddings = model.encode(all_skills)\n",
        "\n",
        "        # Создаем матрицу схожести\n",
        "        similarity_matrix = cosine_similarity(skill_embeddings)\n",
        "\n",
        "        # Находим соответствия\n",
        "        matched = []\n",
        "        for j_skill in job_skills:\n",
        "            idx = all_skills.index(j_skill)\n",
        "            similarities = similarity_matrix[idx]\n",
        "\n",
        "            # Находим лучшее совпадение среди навыков кандидата\n",
        "            best_match = max([\n",
        "                (similarities[all_skills.index(c_skill)], c_skill)    # Сходство и название навыка кандидата\n",
        "                for c_skill in candidate_skills\n",
        "            ], default=(0, None))    # Если совпадений нет, возвращаем (0, None)\n",
        "\n",
        "            if best_match[0] >= 0.7:     # Если сходство превышает порог 0.7, считаем навык совпадающим\n",
        "                matched.append(j_skill)  # Добавляем навык в список совпадающих\n",
        "\n",
        "        # Возвращаем результат в виде словаря\n",
        "        return {\n",
        "            'match_percent': len(matched)/len(job_skills)*100,    # Процент совпадения навыков\n",
        "            'matched_skills': matched,    # Список совпадающих навыков\n",
        "            'missing_skills': list(set(job_skills) - set(matched))     # Список недостающих навыков\n",
        "        }\n",
        "\n",
        "    # Обработка исключений\n",
        "    except Exception as e:\n",
        "        print(f\"Matching error: {str(e)}\")     # Выводим сообщение об ошибке\n",
        "        return {'match_percent': 0, 'matched_skills': [], 'missing_skills': job_skills}    # Возвращаем нулевое соответствие в случае ошибки"
      ],
      "metadata": {
        "id": "RjjUlmj4lmvr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Основной процесс\n",
        "job_data, specialists_data, skill_db = load_data()\n",
        "\n",
        "# Генерация эмбеддингов для кандидатов\n",
        "def get_specialist_embedding(spec):\n",
        "    # Объединяем навыки и опыт в один текст\n",
        "    combined_text = spec['skills'] + ' ' + ' '.join(spec['experience'].keys())\n",
        "\n",
        "    # Кодируем объединенный текст (аналогично вакансиям)\n",
        "    return model.encode(combined_text)\n",
        "\n",
        "# Подготовка индекса FAISS\n",
        "def prepare_faiss_index(specialists):\n",
        "    embeddings = model.encode([s['skills'] + ' ' + ' '.join(s['experience'].keys()) for s in specialists])\n",
        "    embeddings = np.array(embeddings).astype('float32')\n",
        "    faiss.normalize_L2(embeddings)\n",
        "\n",
        "    dimension = model.get_sentence_embedding_dimension()  # Получаем размерность модели\n",
        "    index = faiss.IndexFlatIP(dimension) # Создаем индекс FAISS\n",
        "    index.add(embeddings)  # Добавляем векторы в индекс\n",
        "    return index\n",
        "\n",
        "# Основной процесс\n",
        "index = prepare_faiss_index(specialists_data) # Подготовка индекса FAISS"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-oeYCNrpltVs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Поиск подходящих кандидатов для каждой вакансии\n",
        "results = {}\n",
        "for job_id, job in job_data.items():\n",
        "    job_emb = model.encode(job['requirements'])  # Кодируем требования вакансии\n",
        "    faiss.normalize_L2(job_emb.reshape(1, -1)) # Нормализуем вектор\n",
        "\n",
        "    # Поиск ближайших кандидатов с использованием FAISS\n",
        "    scores, indices = index.search(job_emb.reshape(1, -1).astype('float32'), 10)\n",
        "\n",
        "    candidates = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "\n",
        "        spec = specialists_data[idx]\n",
        "        match_info = calculate_match(job, spec, skill_db) # Расчет соответствия\n",
        "\n",
        "        # Комбинированный балл (70% от FAISS, 30% от соответствия навыков)\n",
        "        combined_score = 0.7 * score + 0.3 * (match_info['match_percent'] / 100)\n",
        "\n",
        "        candidates.append({\n",
        "            'name': spec['name'],\n",
        "            'faiss_score': float(score),\n",
        "            'combined_score': combined_score,\n",
        "            **match_info\n",
        "        })\n",
        "\n",
        "    results[job_id] = sorted(candidates, key=lambda x: -x['combined_score'])[:5] # Сортировка по комбинированному баллу"
      ],
      "metadata": {
        "id": "mUslhMaZl-fS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IBxK4Jx8txom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a82e5f-9903-4c40-e59f-244d43e2fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"job_id\": \"6724e2726fa02b99fe3c3410\",\n",
            "    \"requirements\": \"Стек: 1С-Битрикс: Enterprise (Битрикс24/БУС), PHP 7.4+ , MySQL 8, Memcache, Redis, git, VueJS; Stack: 1C-Bitrix: Enterprise (Bitrix24/BUS), PHP 7.4+ , MySQL 8, Memcache, Redis, git, VueJS; Имеет опыт программирования от 4 лет; He has programming experience of 4 years or more; Умеет оценивать сроки и сообщать о рисках, вовремя сигнализировать о проблеме; Able to assess deadlines and communicate risks, signalling a problem in a timely manner; Знает как реализовать требуемую функциональность любой сложности как на базе CMS Битрикс используя штатные средства и/или API, так и на чистом PHP; Knows how to implement the required functionality of any complexity both on the basis of CMS Bitrix using in-house tools and/or API, and on pure PHP; Знает, в каких случаях стандартные инструменты и технологии будут неэффективными; Knows when standard tools and techniques will be ineffective; Ищет неэффективные места в коде/архитектуре/тестовых моделях; Looks for inefficiencies in code/architecture/test models; Пополняет технический бэклог команды; Fills out the team's technical backlog; Умеет читать и разбираться в чужом коде; Able to read and understand other people's code; Опыт работы с БУС и/или Битрикс24 коробочная версия; Experience with BUS and/or Bitrix24 boxed version; Опыт разработки взаимодействующих между собой систем; Experience of developing systems that interact with each other; Уверенные знания архитектурных паттернов и базовых принципов хорошего кода; Strong knowledge of architectural patterns and basic principles of good code; Знания системы контроля версии git; Knowledge of the git version control system; Умение работать в *nix подобных системах; Ability to work in *nix like systems; Опыт работы в IDE (используем PhpStorm); Experience in IDE (we use PhpStorm); Опыт работы с любым JS фреймворком: React, Vue, Angular; Experience with any JS framework: React, Vue, Angular; Отличные знания SQL в общем, опыт c MySQL в частности: Оптимизация запросов, работа индексов, понимание отличий между движками таблиц, блокировки. Excellent knowledge of SQL in general, experience with MySQL in particular: Query optimisation, indexes, understanding of differences between table engines, locking.\",\n",
            "    \"candidates\": [\n",
            "        {\n",
            "            \"name\": \"Павлов Владимир Августович\",\n",
            "            \"faiss_score\": 0.6479015350341797,\n",
            "            \"combined_score\": 0.45353107452392577,\n",
            "            \"match_percent\": 0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": [\n",
            "                \"битрикс24\",\n",
            "                \"битрикс\",\n",
            "                \"1с-битрикс\",\n",
            "                \"1с-битрикс24\",\n",
            "                \"координация и контроль сроков\",\n",
            "                \"проработка интеграции интернет-магазина с crm-системой заказчика на базе битрикс24\",\n",
            "                \"контроль соблюдения сроков и дедлайнов\",\n",
            "                \"определение сроков\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Васильев Юлиан Ефимьевич\",\n",
            "            \"faiss_score\": 0.6216899156570435,\n",
            "            \"combined_score\": 0.4351829409599304,\n",
            "            \"match_percent\": 0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": [\n",
            "                \"битрикс24\",\n",
            "                \"битрикс\",\n",
            "                \"1с-битрикс\",\n",
            "                \"1с-битрикс24\",\n",
            "                \"координация и контроль сроков\",\n",
            "                \"проработка интеграции интернет-магазина с crm-системой заказчика на базе битрикс24\",\n",
            "                \"контроль соблюдения сроков и дедлайнов\",\n",
            "                \"определение сроков\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Родионов Амвросий Анатольевич\",\n",
            "            \"faiss_score\": 0.6108769178390503,\n",
            "            \"combined_score\": 0.4276138424873352,\n",
            "            \"match_percent\": 0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": [\n",
            "                \"битрикс24\",\n",
            "                \"битрикс\",\n",
            "                \"1с-битрикс\",\n",
            "                \"1с-битрикс24\",\n",
            "                \"координация и контроль сроков\",\n",
            "                \"проработка интеграции интернет-магазина с crm-системой заказчика на базе битрикс24\",\n",
            "                \"контроль соблюдения сроков и дедлайнов\",\n",
            "                \"определение сроков\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Иванов Станимир Изотович\",\n",
            "            \"faiss_score\": 0.6096856594085693,\n",
            "            \"combined_score\": 0.4267799615859985,\n",
            "            \"match_percent\": 0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": [\n",
            "                \"битрикс24\",\n",
            "                \"битрикс\",\n",
            "                \"1с-битрикс\",\n",
            "                \"1с-битрикс24\",\n",
            "                \"координация и контроль сроков\",\n",
            "                \"проработка интеграции интернет-магазина с crm-системой заказчика на базе битрикс24\",\n",
            "                \"контроль соблюдения сроков и дедлайнов\",\n",
            "                \"определение сроков\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Артемьев Михаил Ефимьевич\",\n",
            "            \"faiss_score\": 0.6087338924407959,\n",
            "            \"combined_score\": 0.42611372470855713,\n",
            "            \"match_percent\": 0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": [\n",
            "                \"битрикс24\",\n",
            "                \"битрикс\",\n",
            "                \"1с-битрикс\",\n",
            "                \"1с-битрикс24\",\n",
            "                \"координация и контроль сроков\",\n",
            "                \"проработка интеграции интернет-магазина с crm-системой заказчика на базе битрикс24\",\n",
            "                \"контроль соблюдения сроков и дедлайнов\",\n",
            "                \"определение сроков\"\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Пример вывода\n",
        "job_id_to_search = \"6724e2726fa02b99fe3c3410\"\n",
        "report = {\n",
        "    \"job_id\": job_id_to_search,\n",
        "    \"requirements\": job_data[job_id_to_search]['requirements'],\n",
        "    \"candidates\": results[job_id_to_search][:5]\n",
        "}\n",
        "\n",
        "# Вывод отчета в формате JSON\n",
        "print(json.dumps(report, indent=4, ensure_ascii=False))"
      ]
    }
  ]
}